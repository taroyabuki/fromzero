{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11\n",
    "\n",
    "## 11.1 Kerasによる回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import activations, callbacks, layers, models\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
    "          '/fromzero/master/data/wine.csv')\n",
    "tmp = pd.read_csv(my_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = shuffle(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scaler = StandardScaler()\n",
    "X = my_scaler.fit_transform(\n",
    "    my_data.drop(columns=['LPRICE2']))\n",
    "y = my_data['LPRICE2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 3, 100)\n",
    "plt.plot(x, activations.relu(x))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('ReLU(x)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = models.Sequential()\n",
    "my_model.add(layers.Dense(units=3, activation='relu', input_shape=[4]))\n",
    "my_model.add(layers.Dense(units=1))\n",
    "\n",
    "my_model.summary() # ネットワークの概要\n",
    "#> Model: \"sequential\"\n",
    "#> _________________________________________________________________\n",
    "#> Layer (type)                 Output Shape              Param #\n",
    "#> =================================================================\n",
    "#> dense (Dense)                (None, 3)                 15\n",
    "#> _________________________________________________________________\n",
    "#> dense_1 (Dense)              (None, 1)                 4\n",
    "#> =================================================================\n",
    "#> Total params: 19\n",
    "#> Trainable params: 19\n",
    "#> Non-trainable params: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(\n",
    "    loss='mse',\n",
    "    optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cb = callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_history = my_model.fit(\n",
    "    x=X,\n",
    "    y=y,\n",
    "    validation_split=0.25,\n",
    "    batch_size=10,\n",
    "    epochs=500,\n",
    "    callbacks=[my_cb],\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(my_history.history)\n",
    "tmp.plot(xlabel='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.iloc[-1, ]\n",
    "#> loss        0.192743\n",
    "#> val_loss    0.342249\n",
    "#> Name: 499, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = my_model.predict(X)\n",
    "((y_.ravel() - y)**2).mean()\n",
    "#> 0.23050613964540986"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Kerasによる分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from keras import callbacks, layers, losses, models\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "tmp = sm.datasets.get_rdataset('iris', 'datasets').data\n",
    "my_data = shuffle(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scaler = StandardScaler()\n",
    "X = my_scaler.fit_transform(\n",
    "    my_data.drop(columns=['Species']))\n",
    "my_enc = LabelEncoder()\n",
    "y = my_enc.fit_transform(\n",
    "    my_data['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = models.Sequential()\n",
    "my_model.add(layers.Dense(units=3, activation='relu', input_shape=[4]))\n",
    "my_model.add(layers.Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer='rmsprop',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cb = callbacks.EarlyStopping(\n",
    "    patience=20,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "my_history = my_model.fit(\n",
    "    x=X,\n",
    "    y=y,\n",
    "    validation_split=0.25,\n",
    "    batch_size=10,\n",
    "    epochs=500,\n",
    "    callbacks=[my_cb],\n",
    "    verbose=0)\n",
    "\n",
    "tmp = pd.DataFrame(my_history.history)\n",
    "tmp.plot(xlabel='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.iloc[-1, ]\n",
    "#> loss            0.067497\n",
    "#> accuracy        0.973214\n",
    "#> val_loss        0.143529\n",
    "#> val_accuracy    0.921053"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = my_model.predict(X)\n",
    "y_ = np.argmax(tmp, axis=-1)\n",
    "(y_ == y).mean()\n",
    "#> 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2.1 交差エントロピー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log([0.8, 0.7, 0.3, 0.8]).mean()\n",
    "#> 0.5017337127232719\n",
    "\n",
    "-np.log([0.7, 0.6, 0.2, 0.7]).mean()\n",
    "#> 0.708403356019389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [2, 1, 0, 1]\n",
    "y_1 = [[0.1, 0.1, 0.8],\n",
    "       [0.1, 0.7, 0.2],\n",
    "       [0.3, 0.4, 0.3],\n",
    "       [0.1, 0.8, 0.1]]\n",
    "y_2 = [[0.1, 0.2, 0.7],\n",
    "       [0.2, 0.6, 0.2],\n",
    "       [0.2, 0.5, 0.3],\n",
    "       [0.2, 0.7, 0.1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_1).numpy().mean(),\n",
    " losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_2).numpy().mean()]\n",
    "#> [0.5017337, 0.70840335]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 MNIST：手書き数字の分類\n",
    "\n",
    "### 11.3.1 データの形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from random import sample\n",
    "from keras import callbacks, layers, models\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape\n",
    "#> (60000, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(linewidth=170)\n",
    "x_train[4, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(x_train[4, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train\n",
    "#> array([5, 0, 4, ..., 5, 6, 8],\n",
    "#>       dtype=uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min(), x_train.max()\n",
    "#> (0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test  = x_test  / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index = sample(range(60000), 6000)\n",
    "x_train = x_train[my_index, :, :]\n",
    "y_train = y_train[my_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.2 多層パーセプトロン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = models.Sequential()\n",
    "my_model.add(layers.Flatten(input_shape=[28, 28]))\n",
    "my_model.add(layers.Dense(units=256, activation=\"relu\"))\n",
    "my_model.add(layers.Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "my_model.summary()\n",
    "#> Model: \"sequential\"\n",
    "#> _________________________________________________________________\n",
    "#> Layer (type)                 Output Shape              Param #\n",
    "#> =================================================================\n",
    "#> flatten (Flatten)            (None, 784)               0\n",
    "#> _________________________________________________________________\n",
    "#> dense (Dense)                (None, 256)               200960\n",
    "#> _________________________________________________________________\n",
    "#> dense_1 (Dense)              (None, 10)                2570\n",
    "#> =================================================================\n",
    "#> Total params: 203,530\n",
    "#> Trainable params: 203,530\n",
    "#> Non-trainable params: 0\n",
    "#> _________________________________________________________________\n",
    "\n",
    "my_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer='rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "my_cb = callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_history = my_model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    callbacks=[my_cb],\n",
    "    verbose=0)\n",
    "\n",
    "tmp = pd.DataFrame(my_history.history)\n",
    "tmp.plot(xlabel='epoch', style='o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = my_model.predict(x_test)\n",
    "y_ = np.argmax(tmp, axis=-1)\n",
    "confusion_matrix(y_true=y_test,\n",
    "                 y_pred=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#> [[ 962    0    2    1    1    2    7    1    2    2]\n",
    "#>  [   0 1123    4    0    0    1    3    0    4    0]\n",
    "#>  [  11    4  954   11    6    2    7    9   26    2]\n",
    "#>  [   3    0   20  930    2   12    2   11   21    9]\n",
    "#>  [   1    1    7    0  927    1   11    1    5   28]\n",
    "#>  [  10    1    3   16    4  812   11    7   24    4]\n",
    "#>  [   9    3    4    0    9   10  919    0    4    0]\n",
    "#>  [   3    6   17    4   11    0    0  965    2   20]\n",
    "#>  [   8    4    6   12    6    9    9    7  901   12]\n",
    "#>  [   9    8    0    8   31    4    1   14    7  927]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_ == y_test).mean()\n",
    "#> 0.942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.evaluate(x=x_test, y=y_test)\n",
    "#> [0.20125965774059296,\n",
    "#>  0.9419999718666077]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3.3 畳み込みニューラルネットワーク（CNN）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2d = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test2d = x_test.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.3.1 単純なCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = models.Sequential()\n",
    "my_model.add(layers.Conv2D(filters=32, kernel_size=3, # 畳み込み層\n",
    "                           activation='relu',\n",
    "                           input_shape=[28, 28, 1]))\n",
    "my_model.add(layers.MaxPooling2D(pool_size=2))        # プーリング層\n",
    "my_model.add(layers.Flatten())\n",
    "my_model.add(layers.Dense(128, activation='relu'))\n",
    "my_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "my_model.summary()\n",
    "#> Model: \"sequential\"\n",
    "#> _________________________________________________________________\n",
    "#> Layer (type)                 Output Shape              Param #\n",
    "#> =================================================================\n",
    "#> conv2d (Conv2D)              (None, 26, 26, 32)        320\n",
    "#> _________________________________________________________________\n",
    "#> max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0\n",
    "#> _________________________________________________________________\n",
    "#> flatten (Flatten)            (None, 5408)              0\n",
    "#> _________________________________________________________________\n",
    "#> dense (Dense)                (None, 128)               692352\n",
    "#> _________________________________________________________________\n",
    "#> dense_1 (Dense)              (None, 10)                1290\n",
    "#> =================================================================\n",
    "#> Total params: 693,962\n",
    "#> Trainable params: 693,962\n",
    "#> Non-trainable params: 0\n",
    "#> _________________________________________________________________\n",
    "\n",
    "my_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer='rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "my_cb = EarlyStopping(patience=5,\n",
    "                      restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_history = my_model.fit(\n",
    "    x=x_train2d,\n",
    "    y=y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    callbacks=my_cb,\n",
    "    verbose=0)\n",
    "\n",
    "tmp = pd.DataFrame(my_history.history)\n",
    "tmp.plot(xlabel='epoch', style='o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.evaluate(x=x_test2d, y=y_test)\n",
    "#> [0.1359061449766159,\n",
    "#>  0.9581000208854675]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.3.2 LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = models.Sequential()\n",
    "my_model.add(layers.Conv2D(filters=20, kernel_size=5, activation='relu',\n",
    "                           input_shape=(28, 28, 1)))\n",
    "my_model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "my_model.add(layers.Conv2D(filters=20, kernel_size=5, activation='relu'))\n",
    "my_model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "my_model.add(layers.Dropout(rate=0.25))\n",
    "my_model.add(layers.Flatten())\n",
    "my_model.add(layers.Dense(500, activation='relu'))\n",
    "my_model.add(layers.Dropout(rate=0.5))\n",
    "my_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "my_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                 optimizer='rmsprop',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "my_cb = callbacks.EarlyStopping(patience=5,\n",
    "                                restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_history = my_model.fit(\n",
    "    x=x_train2d,\n",
    "    y=y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    callbacks=my_cb,\n",
    "    verbose=0)\n",
    "\n",
    "tmp = pd.DataFrame(my_history.history)\n",
    "tmp.plot(xlabel='epoch', style='o-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.evaluate(x=x_test2d, y=y_test)\n",
    "#> [0.06491111218929291,\n",
    "#>  0.9797000288963318]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11.3.3.3 補足：LeNetが自信満々で間違う例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = my_model.predict(x_test2d)                    # カテゴリに属する確率\n",
    "\n",
    "tmp = pd.DataFrame({\n",
    "    'y_prob': np.max(y_prob, axis=1),                  # 確率の最大値\n",
    "    'y_': np.argmax(y_prob, axis=1),                   # 予測カテゴリ\n",
    "    'y': y_test,                                       # 正解\n",
    "    'id': range(len(y_test))})                         # 番号\n",
    "\n",
    "tmp = tmp[tmp.y_ != tmp.y]                             # 予測がはずれたものを残す\n",
    "my_result = tmp.sort_values('y_prob', ascending=False) # 確率の大きい順に並び替える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_result.head()\n",
    "#>         y_prob  y_  y    id\n",
    "#> 2654  0.999997   1  6  2654\n",
    "#> 1232  0.999988   4  9  1232\n",
    "#> 3520  0.999926   4  6  3520\n",
    "#> 9729  0.999881   6  5  9729\n",
    "#> 2896  0.999765   0  8  2896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    ans = my_result['y'].iloc[i]\n",
    "    id = my_result['id'].iloc[i]\n",
    "    plt.title(f'{ans} ({id})')\n",
    "    plt.imshow(x_test[id])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 AutoML\n",
    "\n",
    "### 11.4.1 H2Oの起動と停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from h2o.automl import H2OAutoML\n",
    "from random import sample\n",
    "\n",
    "h2o.init()\n",
    "h2o.no_progress()\n",
    "# h2o.cluster().shutdown() # 停止"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.2 H2Oのデータフレーム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = ('https://raw.githubusercontent.com/taroyabuki'\n",
    "          '/fromzero/master/data/wine.csv')\n",
    "my_data = pd.read_csv(my_url)\n",
    "my_frame = h2o.H2OFrame(my_data) # 通常のデータフレームをH2OFrameに変換する．\n",
    "# あるいは\n",
    "my_frame = h2o.import_file(my_url, header=1) # データを読み込む．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_frame.head(5)\n",
    "#>   LPRICE2    WRAIN    DEGREES  ...\n",
    "#> ---------  -------  ---------  ...\n",
    "#>  -0.99868      600    17.1167  ...\n",
    "#>  -0.4544       690    16.7333  ...\n",
    "#>  -0.80796      502    17.15    ...\n",
    "#>  -1.50926      420    16.1333  ...\n",
    "#>  -1.71655      582    16.4167  ...\n",
    "\n",
    "# 通常のデータフレームに戻す．\n",
    "h2o.as_list(my_frame).head()\n",
    "# 結果は割愛（見た目は同じ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.3 AutoMLによる回帰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = H2OAutoML(\n",
    "    max_runtime_secs=60)\n",
    "my_model.train(\n",
    "    y='LPRICE2',\n",
    "    training_frame=my_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.leaderboard['rmse'].min()\n",
    "#> 0.2704643402377778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = h2o.as_list(\n",
    "    my_model.predict(my_frame))\n",
    "\n",
    "pd.DataFrame({\n",
    "    'y': my_data['LPRICE2'],\n",
    "    'y_': tmp['predict']}\n",
    ").plot('y', 'y_', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4.4 AutoMLによる分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "my_index = sample(range(60000), 6000)\n",
    "x_train = x_train[my_index, :, :]\n",
    "y_train = y_train[my_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(\n",
    "    x_train.reshape(-1, 28 * 28))\n",
    "y = 'y'\n",
    "tmp[y] = y_train\n",
    "my_train = h2o.H2OFrame(tmp)\n",
    "my_train[y] = my_train[y].asfactor()\n",
    "\n",
    "tmp = pd.DataFrame(\n",
    "    x_test.reshape(-1, 28 * 28))\n",
    "my_test = h2o.H2OFrame(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = H2OAutoML(\n",
    "    max_runtime_secs=120)\n",
    "my_model.train(\n",
    "    y=y,\n",
    "    training_frame=my_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.leaderboard[\n",
    "    'mean_per_class_error'].min()\n",
    "#> 0.06803754348177862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = h2o.as_list(\n",
    "    my_model.predict(my_test))\n",
    "y_ = tmp.predict\n",
    "\n",
    "(y_ == y_test).mean()\n",
    "#> 0.938"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 }
}
